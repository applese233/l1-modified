Checkpoint tracker file does not exist: /disk3/yiran/yaoqi/l1/checkpoints/l1finetune/qwen2.5-1.5B-Instruct-l1_exact/latest_checkpointed_iteration.txt
Training from scratch
test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 0}
validation generation end
delta_score: -0.22829999999999995, reward_response.is_correct: False, num_tokens: 3335, valid_response_length: 4096delta_score: -0.22829999999999995, reward_response.is_correct: False, num_tokens: 3335, valid_response_length: 4096

delta_score: -0.20219999999999994, reward_response.is_correct: False, num_tokens: 332, valid_response_length: 1006delta_score: -0.20219999999999994, reward_response.is_correct: False, num_tokens: 332, valid_response_length: 1006
delta_score: -0.6504, reward_response.is_correct: False, num_tokens: 2658, valid_response_length: 490
delta_score: -0.16169999999999995, reward_response.is_correct: False, num_tokens: 1155, valid_response_length: 616delta_score: -0.16169999999999995, reward_response.is_correct: False, num_tokens: 1155, valid_response_length: 616delta_score: -0.6504, reward_response.is_correct: False, num_tokens: 2658, valid_response_length: 490

delta_score: -0.7757999999999999, reward_response.is_correct: False, num_tokens: 3464, valid_response_length: 878delta_score: -0.9251999999999999, reward_response.is_correct: False, num_tokens: 3499, valid_response_length: 415
delta_score: -0.9251999999999999, reward_response.is_correct: False, num_tokens: 3499, valid_response_length: 415delta_score: -0.7757999999999999, reward_response.is_correct: False, num_tokens: 3464, valid_response_length: 878delta_score: -0.6377999999999999, reward_response.is_correct: False, num_tokens: 1970, valid_response_length: 4096delta_score: -0.5313, reward_response.is_correct: False, num_tokens: 2754, valid_response_length: 983
delta_score: -0.6377999999999999, reward_response.is_correct: False, num_tokens: 1970, valid_response_length: 4096




delta_score: -0.5313, reward_response.is_correct: False, num_tokens: 2754, valid_response_length: 983


reward_tensor's shape : torch.Size([16, 4096])
len reward_extra_infos_dict['reward']: 16
test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 0}
validation generation end
delta_score: -0.7226999999999999, reward_response.is_correct: False, num_tokens: 3860, valid_response_length: 1451
delta_score: -0.7226999999999999, reward_response.is_correct: False, num_tokens: 3860, valid_response_length: 1451delta_score: -0.21660000000000001, reward_response.is_correct: False, num_tokens: 3374, valid_response_length: 4096
delta_score: -0.21660000000000001, reward_response.is_correct: False, num_tokens: 3374, valid_response_length: 4096
delta_score: -0.0020999999999999908, reward_response.is_correct: False, num_tokens: 679, valid_response_length: 686
delta_score: -0.6266999999999999, reward_response.is_correct: False, num_tokens: 2436, valid_response_length: 347

delta_score: -0.6398999999999999, reward_response.is_correct: False, num_tokens: 1963, valid_response_length: 4096delta_score: -0.0020999999999999908, reward_response.is_correct: False, num_tokens: 679, valid_response_length: 686delta_score: -0.8900999999999999, reward_response.is_correct: False, num_tokens: 3692, valid_response_length: 725delta_score: -0.6398999999999999, reward_response.is_correct: False, num_tokens: 1963, valid_response_length: 4096delta_score: -0.6266999999999999, reward_response.is_correct: False, num_tokens: 2436, valid_response_length: 347
delta_score: -0.061799999999999966, reward_response.is_correct: False, num_tokens: 3890, valid_response_length: 4096delta_score: -0.5216999999999999, reward_response.is_correct: False, num_tokens: 2357, valid_response_length: 4096delta_score: -0.8900999999999999, reward_response.is_correct: False, num_tokens: 3692, valid_response_length: 725
delta_score: -0.061799999999999966, reward_response.is_correct: False, num_tokens: 3890, valid_response_length: 4096





delta_score: -0.5216999999999999, reward_response.is_correct: False, num_tokens: 2357, valid_response_length: 4096

reward_tensor's shape : torch.Size([16, 4096])
len reward_extra_infos_dict['reward']: 32
test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 0}
validation generation end
delta_score: -0.07950000000000002, reward_response.is_correct: False, num_tokens: 689, valid_response_length: 424delta_score: -0.07950000000000002, reward_response.is_correct: False, num_tokens: 689, valid_response_length: 424
delta_score: -0.5966999999999999, reward_response.is_correct: False, num_tokens: 2479, valid_response_length: 490
delta_score: -0.1572, reward_response.is_correct: False, num_tokens: 1484, valid_response_length: 960
delta_score: -0.5966999999999999, reward_response.is_correct: False, num_tokens: 2479, valid_response_length: 490delta_score: -0.12029999999999996, reward_response.is_correct: False, num_tokens: 648, valid_response_length: 1049
delta_score: -0.1572, reward_response.is_correct: False, num_tokens: 1484, valid_response_length: 960

delta_score: -0.8402999999999999, reward_response.is_correct: False, num_tokens: 1295, valid_response_length: 4096delta_score: -0.8402999999999999, reward_response.is_correct: False, num_tokens: 1295, valid_response_length: 4096delta_score: -0.7217999999999999, reward_response.is_correct: False, num_tokens: 2762, valid_response_length: 356
delta_score: -0.7217999999999999, reward_response.is_correct: False, num_tokens: 2762, valid_response_length: 356delta_score: -0.7910999999999999, reward_response.is_correct: False, num_tokens: 3408, valid_response_length: 771

delta_score: -0.12029999999999996, reward_response.is_correct: False, num_tokens: 648, valid_response_length: 1049delta_score: -0.7910999999999999, reward_response.is_correct: False, num_tokens: 3408, valid_response_length: 771delta_score: -0.6684, reward_response.is_correct: False, num_tokens: 2740, valid_response_length: 512
delta_score: -0.6684, reward_response.is_correct: False, num_tokens: 2740, valid_response_length: 512





reward_tensor's shape : torch.Size([16, 4096])
len reward_extra_infos_dict['reward']: 48
test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 0}
validation generation end
delta_score: -0.6342, reward_response.is_correct: False, num_tokens: 3854, valid_response_length: 1740delta_score: -0.6342, reward_response.is_correct: False, num_tokens: 3854, valid_response_length: 1740

delta_score: -0.8858999999999999, reward_response.is_correct: False, num_tokens: 1143, valid_response_length: 4096delta_score: -0.7614, reward_response.is_correct: False, num_tokens: 3146, valid_response_length: 608

delta_score: -0.6939, reward_response.is_correct: False, num_tokens: 3060, valid_response_length: 747
delta_score: -0.7614, reward_response.is_correct: False, num_tokens: 3146, valid_response_length: 608delta_score: -0.09719999999999995, reward_response.is_correct: False, num_tokens: 1143, valid_response_length: 819delta_score: -0.7679999999999999, reward_response.is_correct: False, num_tokens: 3177, valid_response_length: 617delta_score: -0.7679999999999999, reward_response.is_correct: False, num_tokens: 3177, valid_response_length: 617
delta_score: -0.10260000000000002, reward_response.is_correct: False, num_tokens: 932, valid_response_length: 590

delta_score: -0.10260000000000002, reward_response.is_correct: False, num_tokens: 932, valid_response_length: 590
delta_score: -0.6939, reward_response.is_correct: False, num_tokens: 3060, valid_response_length: 747


reward_tensor's shape : torch.Size([12, 4096])
len reward_extra_infos_dict['reward']: 60
("Initial validation metrics: {'val-core//reward/mean@2': -0.5073750007199124, "
 "'val-aux//reward/std@2': 0.01314500036338965, "
 "'val-core//reward/best@2/mean': -0.5002767005236819, "
 "'val-core//reward/best@2/std': 0.011063686947745283, "
 "'val-aux//reward/worst@2/mean': -0.5140526609045143, "
 "'val-aux//reward/worst@2/std': 0.011322538982599972}")
step:0 - val-core//reward/mean@2:-0.5073750007199124 - val-aux//reward/std@2:0.01314500036338965 - val-core//reward/best@2/mean:-0.5002767005236819 - val-core//reward/best@2/std:0.011063686947745283 - val-aux//reward/worst@2/mean:-0.5140526609045143 - val-aux//reward/worst@2/std:0.011322538982599972
Training Progress:   0%|          | 0/15114 [00:00<?, ?it/s]Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=784281, ip=172.28.177.94, actor_id=681619b230d8f58db986115f02000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f2fa02b7d40>)
delta_score: -0.20429999999999993, reward_response.is_correct: False, num_tokens: 104, valid_response_length: 785delta_score: -0.6555, reward_response.is_correct: False, num_tokens: 3059, valid_response_length: 874
delta_score: -1.0256999999999998, reward_response.is_correct: False, num_tokens: 3906, valid_response_length: 487
delta_score: -0.06240000000000001, reward_response.is_correct: False, num_tokens: 1669, valid_response_length: 1877delta_score: -0.25259999999999994, reward_response.is_correct: False, num_tokens: 104, valid_response_length: 946

delta_score: -0.022199999999999998, reward_response.is_correct: False, num_tokens: 745, valid_response_length: 819
delta_score: -0.12329999999999997, reward_response.is_correct: False, num_tokens: 1669, valid_response_length: 1258delta_score: -0.0645, reward_response.is_correct: False, num_tokens: 425, valid_response_length: 640
delta_score: -0.08999999999999997, reward_response.is_correct: False, num_tokens: 745, valid_response_length: 1045delta_score: -0.31919999999999993, reward_response.is_correct: False, num_tokens: 2347, valid_response_length: 1283
delta_score: -0.9977999999999999, reward_response.is_correct: False, num_tokens: 3906, valid_response_length: 580
delta_score: -0.6657, reward_response.is_correct: False, num_tokens: 3059, valid_response_length: 840
delta_score: -0.06779999999999997, reward_response.is_correct: False, num_tokens: 425, valid_response_length: 651delta_score: -0.24570000000000003, reward_response.is_correct: False, num_tokens: 235, valid_response_length: 1054
delta_score: -0.4413, reward_response.is_correct: False, num_tokens: 2347, valid_response_length: 876

delta_score: -0.2669999999999999, reward_response.is_correct: False, num_tokens: 235, valid_response_length: 1125



reward_tensor's shape : torch.Size([16, 4096])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/single_controller/ray/base.py", line 720, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/single_controller/base/decorator.py", line 430, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/workers/fsdp_workers.py", line 735, in update_actor
    metrics = self.actor.update_policy(data=data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/utils/profiler/performance.py", line 105, in f
    return self.log(decorated_function, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/utils/profiler/performance.py", line 118, in log
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/workers/actor/dp_actor.py", line 466, in update_policy
    loss.backward()
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.64 GiB. GPU 0 has a total capacity of 79.25 GiB of which 711.25 MiB is free. Including non-PyTorch memory, this process has 78.52 GiB memory in use. Of the allocated memory 76.74 GiB is allocated by PyTorch, with 86.00 MiB allocated in private pools (e.g., CUDA Graphs), and 127.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=784283, ip=172.28.177.94, actor_id=f2509c676f5b357ce19901de02000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f755446bdd0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/single_controller/ray/base.py", line 720, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/single_controller/base/decorator.py", line 430, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/workers/fsdp_workers.py", line 735, in update_actor
    metrics = self.actor.update_policy(data=data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/utils/profiler/performance.py", line 105, in f
    return self.log(decorated_function, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/utils/profiler/performance.py", line 118, in log
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/workers/actor/dp_actor.py", line 466, in update_policy
    loss.backward()
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.64 GiB. GPU 0 has a total capacity of 79.25 GiB of which 751.25 MiB is free. Including non-PyTorch memory, this process has 78.48 GiB memory in use. Of the allocated memory 76.74 GiB is allocated by PyTorch, with 86.00 MiB allocated in private pools (e.g., CUDA Graphs), and 87.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=784282, ip=172.28.177.94, actor_id=81c538960e30bfe6ccdaeea402000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f76d9a22780>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/single_controller/ray/base.py", line 720, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/single_controller/base/decorator.py", line 430, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/workers/fsdp_workers.py", line 735, in update_actor
    metrics = self.actor.update_policy(data=data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/utils/profiler/performance.py", line 105, in f
    return self.log(decorated_function, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/utils/profiler/performance.py", line 118, in log
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/verl/workers/actor/dp_actor.py", line 466, in update_policy
    loss.backward()
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.64 GiB. GPU 0 has a total capacity of 79.25 GiB of which 751.25 MiB is free. Including non-PyTorch memory, this process has 78.48 GiB memory in use. Of the allocated memory 76.74 GiB is allocated by PyTorch, with 86.00 MiB allocated in private pools (e.g., CUDA Graphs), and 87.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
