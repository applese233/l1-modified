_wandb:
    value:
        cli_version: 0.21.1
        e:
            v5rhsyvld84fjyaa1wmb733ofpdpywrt:
                args:
                    - --node-ip-address=172.28.177.94
                    - --node-manager-port=42109
                    - --object-store-name=/disk3/yiran/yaoqi/ray_tmp/ray/session_2025-08-13_09-28-32_644706_4019272/sockets/plasma_store
                    - --raylet-name=/disk3/yiran/yaoqi/ray_tmp/ray/session_2025-08-13_09-28-32_644706_4019272/sockets/raylet
                    - --redis-address=None
                    - --metrics-agent-port=43374
                    - --logging-rotate-bytes=536870912
                    - --logging-rotate-backup-count=5
                    - --runtime-env-agent-port=64363
                    - --gcs-address=172.28.177.94:6379
                    - --session-name=session_2025-08-13_09-28-32_644706_4019272
                    - --temp-dir=/disk3/yiran/yaoqi/ray_tmp/ray
                    - --webui=127.0.0.1:8265
                    - --cluster-id=07882c8fc3052404d2bbc7ea4734e9bf2779eba57ed0f4e2b534dbe5
                    - --startup-token=256
                    - --worker-launch-time-ms=1755077344820
                    - --node-id=75eb52c54cf808dcba89ab978d0d7010e9fa36fd78bfc044ddab3eca
                    - --runtime-env-hash=1830736042
                    - --enable-resource-isolation=false
                cpu_count: 128
                cpu_count_logical: 256
                cudaVersion: "12.6"
                disk:
                    /:
                        total: "1880103190528"
                        used: "1751851954176"
                email: changliu11@g.ucla.edu
                executable: /home/yiran/miniconda3/envs/l1-yaoqi/bin/python3.12
                git:
                    commit: 93dd330102f49450e1bc8227ad8979f8b5482e44
                    remote: https://github.com/cmu-l3/l1.git
                gpu: NVIDIA A100-SXM4-80GB
                gpu_count: 8
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-2922e67b-0900-4c64-fe95-94c2713fe859
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-11750985-0f1a-c9c3-112e-07931e88905d
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-92effd43-a936-4134-9efe-87a0f9a65135
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-0a3dab48-1127-d79f-8c45-b0193134af7e
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-c65a533f-c2b5-8ec1-f325-03c3719c36b1
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-7afd9180-f2fd-e76f-ae65-65ee06b26c49
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-67d30557-f97c-291c-b15b-74501dcfec5a
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-78f68a65-4de8-5638-e55d-d8d26692f03b
                host: dgx.d2.comp.nus.edu.sg
                memory:
                    total: "2164271816704"
                os: Linux-5.4.0-208-generic-x86_64-with-glibc2.31
                program: /home/yiran/miniconda3/envs/l1-yaoqi/lib/python3.12/site-packages/ray/_private/workers/default_worker.py
                python: CPython 3.12.11
                root: /home/yiran/yaoqi_workplace/l1
                startedAt: "2025-08-13T09:31:39.221492Z"
                writerId: v5rhsyvld84fjyaa1wmb733ofpdpywrt
        m: []
        python_version: 3.12.11
        t:
            "1":
                - 1
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 71
                - 98
                - 105
            "2":
                - 1
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 71
                - 98
                - 105
            "3":
                - 2
                - 13
                - 16
                - 61
            "4": 3.12.11
            "5": 0.21.1
            "6": 4.55.0
            "12": 0.21.1
            "13": linux-x86_64
actor_rollout_ref:
    value:
        actor:
            _target_: verl.workers.config.FSDPActorConfig
            checkpoint:
                contents:
                    - model
                    - optimizer
                    - extra
            clip_ratio: 0.2
            clip_ratio_c: 3
            clip_ratio_high: 0.2
            clip_ratio_low: 0.2
            entropy_coeff: 0.001
            fsdp_config:
                _target_: verl.workers.config.FSDPEngineConfig
                fsdp_size: -1
                model_dtype: bfloat16
                optimizer_offload: false
                param_offload: false
                wrap_policy:
                    min_num_params: 0
            grad_clip: 1
            kl_loss_coef: 0.001
            kl_loss_type: low_var_kl
            loss_agg_mode: token-mean
            optim:
                _target_: verl.workers.config.FSDPOptimizerConfig
                lr: 1e-06
                lr_warmup_steps: -1
                lr_warmup_steps_ratio: 0
                min_lr_ratio: null
                total_training_steps: 3777
                warmup_style: constant
                weight_decay: 0.01
            ppo_epochs: 1
            ppo_max_token_len_per_gpu: 32768
            ppo_micro_batch_size: null
            ppo_micro_batch_size_per_gpu: null
            ppo_mini_batch_size: 16
            shuffle: false
            strategy: fsdp
            ulysses_sequence_parallel_size: 1
            use_dynamic_bsz: true
            use_kl_loss: true
            use_torch_compile: true
        hybrid_engine: true
        model:
            dtype: bfloat16
            enable_gradient_checkpointing: true
            external_lib: null
            path: Qwen/Qwen2.5-1.5B-Instruct
            use_remove_padding: true
        ref:
            entropy_from_logits_with_chunking: false
            fsdp_config:
                _target_: verl.workers.config.FSDPEngineConfig
                model_dtype: bfloat16
                param_offload: true
                wrap_policy:
                    min_num_params: 0
            log_prob_max_token_len_per_gpu: 32768
            log_prob_micro_batch_size: null
            log_prob_micro_batch_size_per_gpu: null
            log_prob_use_dynamic_bsz: true
            ulysses_sequence_parallel_size: 1
        rollout:
            _target_: verl.workers.config.RolloutConfig
            calculate_log_probs: true
            disable_log_stats: true
            do_sample: true
            dtype: bfloat16
            enable_chunked_prefill: true
            enforce_eager: false
            free_cache_engine: false
            gpu_memory_utilization: 0.85
            ignore_eos: false
            load_format: dummy_dtensor
            log_prob_max_token_len_per_gpu: 32768
            log_prob_micro_batch_size: null
            log_prob_micro_batch_size_per_gpu: null
            log_prob_use_dynamic_bsz: true
            max_model_len: null
            max_num_batched_tokens: 32768
            max_num_seqs: 1024
            mode: sync
            "n": 16
            name: vllm
            prompt_length: 1024
            response_length: 4096
            temperature: 0.6
            tensor_model_parallel_size: 2
            top_k: -1
            top_p: 1
            val_kwargs:
                _target_: verl.workers.config.SamplingConfig
                do_sample: false
                "n": 16
                temperature: 0.6
                top_k: -1
                top_p: 1
algorithm:
    value:
        _target_: verl.trainer.config.AlgoConfig
        adv_estimator: grpo
        gamma: 1
        kl_ctrl:
            horizon: 10000
            kl_coef: 0.001
            target_kl: 0.1
            type: fixed
        kl_penalty: kl
        lam: 1
        use_kl_in_reward: false
critic:
    value:
        checkpoint:
            contents:
                - model
                - optimizer
                - extra
        cliprange_value: 0.5
        enable: false
        forward_max_token_len_per_gpu: 32768
        forward_micro_batch_size: null
        forward_micro_batch_size_per_gpu: null
        grad_clip: 1
        model:
            dtype: bfloat16
            enable_gradient_checkpointing: true
            external_lib: null
            fsdp_config:
                fsdp_size: -1
                optimizer_offload: false
                param_offload: false
                wrap_policy:
                    min_num_params: 0
            path: ~/models/deepseek-llm-7b-chat
            tokenizer_path: Qwen/Qwen2.5-1.5B-Instruct
            use_remove_padding: false
        optim:
            lr: 1e-05
            lr_warmup_steps_ratio: 0
            min_lr_ratio: null
            total_training_steps: 3777
            warmup_style: constant
            weight_decay: 0.01
        ppo_epochs: 1
        ppo_max_token_len_per_gpu: 32768
        ppo_micro_batch_size: null
        ppo_micro_batch_size_per_gpu: null
        ppo_mini_batch_size: 16
        rollout_n: 16
        shuffle: false
        strategy: fsdp
        ulysses_sequence_parallel_size: 1
        use_dynamic_bsz: true
custom_reward_function:
    value:
        name: compute_score
        path: null
data:
    value:
        dataloader_num_workers: 4
        filter_overlong_prompts: true
        filter_overlong_prompts_workers: 1
        image_key: images
        max_prompt_length: 1024
        max_response_length: 4096
        prompt_key: prompt
        return_raw_chat: false
        return_raw_input_ids: false
        reward_fn_key: data_source
        sampler:
            class_name: null
            class_path: null
        shuffle: true
        tokenizer: null
        train_batch_size: 32
        train_files: /disk3/yiran/yaoqi/l1/data_exact/train.parquet
        truncation: error
        val_batch_size: 128
        val_files: /disk3/yiran/yaoqi/l1/data_exact/aime.parquet
global_profiler:
    value:
        _target_: verl.utils.profiler.ProfilerConfig
        global_tool_config:
            nsys:
                _target_: verl.utils.profiler.config.NsightToolConfig
                controller_nsight_options:
                    cuda-graph-trace: graph
                    cuda-memory-usage: "true"
                    trace: cuda,nvtx,cublas,ucx
                discrete: false
                worker_nsight_options:
                    capture-range: cudaProfilerApi
                    capture-range-end: null
                    cuda-graph-trace: graph
                    cuda-memory-usage: "true"
                    kill: none
                    trace: cuda,nvtx,cublas,ucx
        profile_continuous_steps: false
        save_path: outputs/profile
        steps: null
        tool: null
ray_init:
    value:
        num_cpus: null
        timeline_json_file: null
reward_config:
    value:
        alpha: 0.0003
        linear_reward: true
        multiplier_reward: false
        sigmoid_reward: false
reward_model:
    value:
        enable: false
        forward_max_token_len_per_gpu: 32768
        launch_reward_fn_async: false
        max_length: null
        micro_batch_size: null
        micro_batch_size_per_gpu: null
        model:
            external_lib: null
            fsdp_config:
                fsdp_size: -1
                param_offload: false
                wrap_policy:
                    min_num_params: 0
            input_tokenizer: Qwen/Qwen2.5-1.5B-Instruct
            path: ~/models/FsfairX-LLaMA3-RM-v0.1
            use_remove_padding: false
        reward_manager: naive
        strategy: fsdp
        ulysses_sequence_parallel_size: 1
        use_dynamic_bsz: true
trainer:
    value:
        balance_batch: true
        critic_warmup: 0
        default_hdfs_dir: null
        default_local_dir: /disk3/yiran/yaoqi/l1/checkpoints/l1finetune/qwen2.5-1.5B-Instruct-l1_exact
        del_local_ckpt_after_load: false
        device: cuda
        experiment_name: qwen2.5-1.5B-Instruct-l1_exact
        log_val_generations: 0
        logger:
            - console
            - wandb
        max_actor_ckpt_to_keep: null
        max_critic_ckpt_to_keep: null
        n_gpus_per_node: 8
        nnodes: 1
        project_name: l1finetune
        resume_from_path: null
        resume_mode: auto
        save_freq: 20
        test_freq: 20
        total_epochs: 3
        total_training_steps: null
        val_before_train: true
